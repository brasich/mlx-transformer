{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import mlx.optimizers as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 1, 58, 46, 43, 56, 43]\n",
      "hi there\n"
     ]
    }
   ],
   "source": [
    "stoi = { ch:i for i, ch in enumerate(chars) }\n",
    "itos = { i:ch for i, ch in enumerate(chars) }\n",
    "\n",
    "def encode(input_string):\n",
    "    return [stoi[char] for char in input_string]\n",
    "\n",
    "def decode(input_list):\n",
    "    return ''.join([itos[i] for i in input_list])\n",
    "\n",
    "print(encode('hi there'))\n",
    "print(decode(encode('hi there')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1115394,)\n",
      "mlx.core.int32\n"
     ]
    }
   ],
   "source": [
    "data = mx.array(encode(text))\n",
    "print(data.shape)\n",
    "print(data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18, 47, 56, ..., 15, 47, 58], dtype=int32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is array([18], dtype=int32) the target: array(47, dtype=int32)\n",
      "when input is array([18, 47], dtype=int32) the target: array(56, dtype=int32)\n",
      "when input is array([18, 47, 56], dtype=int32) the target: array(57, dtype=int32)\n",
      "when input is array([18, 47, 56, 57], dtype=int32) the target: array(58, dtype=int32)\n",
      "when input is array([18, 47, 56, 57, 58], dtype=int32) the target: array(1, dtype=int32)\n",
      "when input is array([18, 47, 56, 57, 58, 1], dtype=int32) the target: array(15, dtype=int32)\n",
      "when input is array([18, 47, 56, ..., 58, 1, 15], dtype=int32) the target: array(47, dtype=int32)\n",
      "when input is array([18, 47, 56, ..., 1, 15, 47], dtype=int32) the target: array(58, dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "(4, 8)\n",
      "array([[60, 43, 1, ..., 58, 1, 39],\n",
      "       [8, 0, 0, ..., 17, 17, 26],\n",
      "       [53, 59, 58, ..., 43, 10, 0],\n",
      "       [39, 47, 58, ..., 52, 1, 44]], dtype=int32)\n",
      "targets:\n",
      "(4, 8)\n",
      "array([[43, 1, 51, ..., 1, 39, 1],\n",
      "       [0, 0, 29, ..., 17, 26, 1],\n",
      "       [59, 58, 1, ..., 10, 0, 21],\n",
      "       [47, 58, 1, ..., 1, 44, 53]], dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = mx.random.randint(0, len(data) - block_size, (batch_size,))\n",
    "    ix = [i.item() for i in ix]\n",
    "    x = mx.stack([data[i:i+block_size] for i in ix])\n",
    "    y = mx.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "\n",
    "print('input:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def __call__(self, idx):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits = self(idx)\n",
    "            logits = logits[:, -1, :]\n",
    "            idx_next = mx.random.categorical(logits, num_samples=1)\n",
    "            idx = mx.concatenate((idx, idx_next), axis=-1)\n",
    "        return idx\n",
    "    \n",
    "def loss_fn(model, X, y):\n",
    "    logits = model(X)\n",
    "    B, T, C = logits.shape\n",
    "    logits = logits.reshape(B*T, C)\n",
    "    targets = y.reshape(B*T)\n",
    "    return mx.mean(nn.losses.cross_entropy(logits, targets))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = BigramLanguageModel(vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_grad_fn = nn.value_and_grad(m, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "!,?s!qlTyA.Lmywz K\n",
      "yw:v'ES'rCzb-k'S3RjlM?oUuW&ocO:X\n",
      "j$iyBbzXySh.U- KMV hNA$p;dBBm--WSYuKAHdRFC3CzsNR\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx=mx.zeros((1,1), dtype=mx.int32), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss = array(2.53058, dtype=float32)\n",
      "step 500 loss = array(2.47609, dtype=float32)\n",
      "step 1000 loss = array(2.54961, dtype=float32)\n",
      "step 1500 loss = array(2.48677, dtype=float32)\n",
      "step 2000 loss = array(2.43697, dtype=float32)\n",
      "step 2500 loss = array(2.54745, dtype=float32)\n",
      "step 3000 loss = array(2.41424, dtype=float32)\n",
      "step 3500 loss = array(2.47758, dtype=float32)\n",
      "step 4000 loss = array(2.45294, dtype=float32)\n",
      "step 4500 loss = array(2.52854, dtype=float32)\n",
      "step 5000 loss = array(2.45235, dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for steps in range(5000):\n",
    "    xb, yb = get_batch('train')\n",
    "    loss, grads = loss_and_grad_fn(m, xb, yb)\n",
    "    if steps % 500 == 0:\n",
    "        print(f'step {steps} loss = {loss}')\n",
    "\n",
    "    optimizer.update(m, grads)\n",
    "\n",
    "print(f'step {steps + 1} loss = {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wh.\n",
      "bo ofimyons.\n",
      "BE been whe t o s t beee s d mape ars; my,\n",
      "KI as.\n",
      "Yo bongr tir ter than\n",
      "Bertanthanc\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx=mx.zeros((1,1), dtype=mx.int32), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4999"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
